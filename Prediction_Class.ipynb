{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of Data\n",
    "This part uses the library pandas, that allows us to use an easy way to call the data from the tables. \n",
    "The excel file is located on the same folder and is called Dream9.xlsx. \n",
    "The excel file has two sheets: the first one for training data and the second one for scoring data.\n",
    "The are stored as Dream9_training and Dream9_scoring respectively.\n",
    "If you need to, you also have a variable called Dream9 that contains both tables.\n",
    "\n",
    "I clasified the Variables that appear in the tables with 3 main clasifications:\n",
    "\n",
    "**Dependent**: Those variables that appear on the training Data but not on the scoring Data\n",
    "\n",
    "**Categorical**: Those variables that have non-numerical values. All of them with the exception on cyto.cat represent binary decitios, like yes or no.\n",
    "\n",
    "**Protein**: The variables that contain data on the protein concentration.\n",
    "\n",
    "To invoke combinations of those variables you can use the magic of Python. I found that a practival way can be:\n",
    "\n",
    "    [v for v in All if (v not in Protein and v in Dependent and v <> 'resp.simple')]\n",
    "\n",
    "You can read that as: *\"Oh!, mighty variable that is a variable who has appeared in all the variables, if you are not a Protein, you are Dependent and you are not called \"resp. simple\" please appear among us\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Dependent**: [u'resp.simple', u'Relapse', u'vital.status', u'Overall_Survival', u'Remission_Duration'] \n",
      "\n",
      "**Categorical**: ['SEX', 'PRIOR.MAL', 'PRIOR.CHEMO', 'PRIOR.XRT', 'Infection', 'cyto.cat', 'ITD', 'D835', 'Ras.Stat', 'resp.simple', 'Relapse', 'vital.status'] \n",
      "\n",
      "**Not Protein**: [u'SEX', u'Age.at.Dx', u'AHD', u'PRIOR.MAL', u'PRIOR.CHEMO', u'PRIOR.XRT', u'Infection', u'cyto.cat', u'ITD', u'D835', u'Ras.Stat', u'resp.simple', u'Relapse', u'vital.status', u'Overall_Survival', u'Remission_Duration', u'WBC', u'ABS.BLST', u'BM.BLAST', u'BM.MONOCYTES', u'BM.PROM', u'PB.BLAST', u'PB.MONO', u'PB.PROM', u'HGB', u'PLT', u'LDH', u'ALBUMIN', u'BILIRUBIN', u'CREATININE', u'FIBRINOGEN', u'CD13', u'CD33', u'CD34', u'CD7', u'CD10', u'CD20', u'HLA.DR', u'CD19'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Open the data and read in pandas\n",
    "import pandas\n",
    "Dream9_training=pandas.read_excel('Dream9.xlsx',\"trainingData\")\n",
    "Dream9_scoring=pandas.read_excel('Dream9.xlsx',\"scoringData\")\n",
    "Dream9=pandas.concat([Dream9_training,Dream9_scoring])\n",
    "\n",
    "#Division of types of Variables\n",
    "All=list(Dream9_training.keys())\n",
    "Sc=list(Dream9_scoring.keys())\n",
    "\n",
    "#Dependent variables are present in the training set but not in the scoring set\n",
    "Dependent=[]\n",
    "for v in All:\n",
    "    if v not in Sc:\n",
    "        Dependent+=[v]\n",
    "print '**Dependent**:',Dependent,'\\n'\n",
    "\n",
    "#Categorical variables have discrete values and can't be measured by euclidean distances\n",
    "Categorical=['SEX', 'PRIOR.MAL', 'PRIOR.CHEMO', 'PRIOR.XRT', 'Infection', 'cyto.cat', \n",
    "             'ITD', 'D835', 'Ras.Stat', 'resp.simple', 'Relapse', 'vital.status']\n",
    "print '**Categorical**:',Categorical,'\\n'\n",
    "\n",
    "#The last 231 variables are proteins\n",
    "Protein=All[-231:]\n",
    "print '**Not Protein**:',[v for v in All if v not in Protein],'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try calling variables below.\n",
    "Also, to call part of the table you can do Table[Columns][rows]. For example:\n",
    "\n",
    "    Dream9[Dependent][:5]\n",
    "\n",
    "You will invoke a table containind the dependent variables in columns and only the first 5 items as rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Relapse', u'vital.status', u'Overall_Survival', u'Remission_Duration']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[variable for variable in All if (variable not in Protein and variable in Dependent and variable <> 'resp.simple')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resp.simple</th>\n",
       "      <th>Relapse</th>\n",
       "      <th>vital.status</th>\n",
       "      <th>Overall_Survival</th>\n",
       "      <th>Remission_Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_id_001</th>\n",
       "      <td>        CR</td>\n",
       "      <td>  No</td>\n",
       "      <td> A</td>\n",
       "      <td> 568.57</td>\n",
       "      <td> 564.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_id_002</th>\n",
       "      <td>        CR</td>\n",
       "      <td> Yes</td>\n",
       "      <td> D</td>\n",
       "      <td> 185.86</td>\n",
       "      <td> 123.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_id_003</th>\n",
       "      <td> RESISTANT</td>\n",
       "      <td> NaN</td>\n",
       "      <td> D</td>\n",
       "      <td>  56.29</td>\n",
       "      <td>    NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_id_004</th>\n",
       "      <td>        CR</td>\n",
       "      <td> Yes</td>\n",
       "      <td> D</td>\n",
       "      <td>  98.14</td>\n",
       "      <td>  63.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_id_005</th>\n",
       "      <td>        CR</td>\n",
       "      <td> Yes</td>\n",
       "      <td> A</td>\n",
       "      <td> 454.71</td>\n",
       "      <td>  97.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             resp.simple Relapse vital.status  Overall_Survival  \\\n",
       "train_id_001          CR      No            A            568.57   \n",
       "train_id_002          CR     Yes            D            185.86   \n",
       "train_id_003   RESISTANT     NaN            D             56.29   \n",
       "train_id_004          CR     Yes            D             98.14   \n",
       "train_id_005          CR     Yes            A            454.71   \n",
       "\n",
       "              Remission_Duration  \n",
       "train_id_001              564.14  \n",
       "train_id_002              123.86  \n",
       "train_id_003                 NaN  \n",
       "train_id_004               63.43  \n",
       "train_id_005               97.57  \n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dream9[Dependent][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "A important step before the prediction is the pre-processing of the data. It allows to create new variables that are more related to the dependent variables. Also we can modify the expected variables to have new results.\n",
    "\n",
    "The tables containing the new data are saved in Qtraining.csv and Qscoring.csv\n",
    "\n",
    "## Making all the variables quantitative\n",
    "To make all the variables quantitative we take all the values that are yes/no, pos/neg F/M and convert them to 1 and 0. In the case that there is no data or not conclusive data we use NaN. \n",
    "\n",
    "In the special case of cyto.cat that has multiple values we create a column for each unique value. Each column contains 1 or 0 depending depending if the data corresponds to that unique value or not.\n",
    "\n",
    "## Preprocessing data for proteins\n",
    "Sometimes a low concentration, as well as a high concentration of the protein can cause illness. If both a high value and a low value can have the same effect on the dependent variables, then there will not be a good correlation. So we are comparing the protein against the mean and squaring the result. (What i mistakenly called normalized)\n",
    "\n",
    "Since the mean is expected to be 0 because the data of all the proteins are mean centered, squaring the result should be similar to the \"Normalization\"\n",
    "\n",
    "Keeping in mind that there may be a correlation if the mean is distant from the data, we also have the possibility of creating new variables, where the correlation between the dependent variables and this squared difference is maximized. (Not implemented yet)\n",
    "\n",
    "## Cutoff of Dependent data.\n",
    "If a patient lives longer than 2 years or has a remission longer than 2 years is considered as a category. Some patients have much longer periods, that may be independent of any variable, because the patient is still alive. We don't want this data interfering with the prediction, so we may suppose that all the patients that live longer than 2 years and a half (130 weeks) live just 130 weeks. We can apply the same logic for Remission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187, 516)\n",
      "(70, 509)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "###############\n",
    "#  Functions  #\n",
    "###############\n",
    "\n",
    "def alias(Series,aliases):\n",
    "    #Changes the values on a Series with aliases as a dict that transform the old values in the new values\n",
    "    new_Series=(Series=='This creates and new series')\n",
    "    for key,data in zip(Series.keys(),Series):\n",
    "        new_Series[key]=False\n",
    "        for val in aliases:\n",
    "            try:\n",
    "                if numpy.isnan(data):\n",
    "                    new_Series[key]=numpy.nan\n",
    "            except:\n",
    "                pass             \n",
    "            if data==val:\n",
    "                new_Series[key]=aliases[val]\n",
    "                break\n",
    "    return new_Series\n",
    "\n",
    "def split(Series,All_Data):\n",
    "    #For Series with multiple values, creates a table with a column for each unique value\n",
    "    #The value is True for the correct column and False for all the other columns\n",
    "    D=[]\n",
    "    for value in All_Data[Series.name].unique():\n",
    "        q=(Series==value)\n",
    "        q.name='%s=%s'%(q.name,value)\n",
    "        D+=[q]\n",
    "    return pandas.concat(D,axis=1)\n",
    "\n",
    "\n",
    "def difference_from_mean(Table,All_Data):\n",
    "    #This function creates a new Table with the values equal to (value-mean)/std\n",
    "    #Since most of the values are already centered around 0 it woul be better to just take the square?\n",
    "    D=[]\n",
    "    for i,var in enumerate(Table.keys()):\n",
    "        m=All_Data[var].mean()\n",
    "        std=All_Data[var].std()\n",
    "        D+=[(Table[var]-m)**2/std]\n",
    "        D[i].name='%s_Normalized'%var\n",
    "    return pandas.concat(D,axis=1)\n",
    "\n",
    "def squared(Table):\n",
    "    #This function squares all the values on a table\n",
    "    D=[]\n",
    "    for i,var in enumerate(Table.keys()):\n",
    "        D+=[Table[var]**2]\n",
    "        D[i].name='%s_Squared'%var\n",
    "    return pandas.concat(D,axis=1)\n",
    "\n",
    "def cutoff(Series,cutoff):\n",
    "    #This function makes values above a threeshold equal to the threeshold\n",
    "    new_Series=Series.copy()\n",
    "    for key,data in zip(Series.keys(),Series):\n",
    "        if data>cutoff:\n",
    "            new_Series[key]=cutoff\n",
    "        else:\n",
    "            new_Series[key]=data\n",
    "    new_Series.name='%s_cut'%Series.name\n",
    "    return new_Series\n",
    "    \n",
    "####################\n",
    "#  Pre-processing  #\n",
    "####################    \n",
    "    \n",
    "def PreProcess(table):\n",
    "    #Select A\n",
    "    Tables=[table[[v for v in table.keys() if v not in Categorical]]]\n",
    "    \n",
    "    #Convert yes/no to 1/0\n",
    "    Alias_Dict={'SEX':{'F':1},'PRIOR.MAL':{'YES':1},'PRIOR.CHEMO':{'YES':1},'PRIOR.XRT':{'YES':1},\n",
    "                'Infection':{'Yes':1},'ITD':{'POS':1,'ND':numpy.nan},'D835':{'POS':1,'ND':numpy.nan},\n",
    "                'Ras.Stat':{'POS':1,'NotDone':numpy.nan},'resp.simple':{'CR':1},'Relapse':{'Yes':1},\n",
    "                'vital.status':{'A':1}}\n",
    "    Aliased=[]\n",
    "    for key in Alias_Dict:\n",
    "        if key in table.keys():\n",
    "            Aliased+=[alias(table[key],Alias_Dict[key])]\n",
    "    Tables+=[pandas.concat(Aliased,axis=1)]\n",
    "    \n",
    "    #Split data that has multiple values\n",
    "    Tables+=[split(table['cyto.cat'],Dream9)]\n",
    "    \n",
    "    #Create new data for protein\n",
    "    #Tables+=[difference_from_mean(table[Protein],Dream9)]\n",
    "    \n",
    "    #Create new data for protein\n",
    "    Tables+=[squared(table[Protein])]\n",
    "    \n",
    "    #Join everything\n",
    "    \n",
    "    Cut=[]\n",
    "    for key in ['Overall_Survival','Remission_Duration']:\n",
    "        if key in table.keys():\n",
    "            Cut+=[cutoff(table[key],130)]\n",
    "    if len(Cut)>0:\n",
    "        Tables+=[pandas.concat(Cut,axis=1)]\n",
    "\n",
    "    return pandas.concat(Tables,axis=1)\n",
    "    \n",
    "#Create the new tables\n",
    "Q_training=PreProcess(Dream9_training)\n",
    "Q_scoring=PreProcess(Dream9_scoring)\n",
    "\n",
    "#Save the tables as csv\n",
    "Q_training.to_csv('Qtraining.csv')\n",
    "Q_scoring.to_csv('Qscoring.csv')\n",
    "\n",
    "#Number of columns and rows of new Table\n",
    "print Q_training.shape\n",
    "print Q_scoring.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations\n",
    "It is useful to find the variables that have most correlation with other variables. If some of the new variables we created are important, they may be shown on this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPM1.3542          -0.252036\n",
      "CD34               -0.241693\n",
      "ERG                -0.215514\n",
      "PIK3CA              0.208228\n",
      "cyto.cat=diploid    0.216598\n",
      "Name: resp.simple, dtype: float64\n",
      "HGB                  -0.215277\n",
      "D835                 -0.214264\n",
      "SMAD5                -0.202269\n",
      "EGFR.pY992_Squared    0.216344\n",
      "GAPDH_Squared         0.223614\n",
      "TP53                  0.232152\n",
      "ITD                   0.243735\n",
      "CD13                  0.265287\n",
      "Name: Relapse, dtype: float64\n",
      "HSP90AA1_B1        -0.278365\n",
      "Age.at.Dx          -0.277940\n",
      "HNRNPK             -0.238282\n",
      "cyto.cat=-5,-7     -0.226312\n",
      "EIF2S1             -0.213093\n",
      "PA2G4.pS65         -0.201985\n",
      "BECN1              -0.200825\n",
      "ITGA2               0.205998\n",
      "WTAP_Squared        0.209763\n",
      "H3K27Me3            0.212390\n",
      "FN1                 0.218321\n",
      "HSPA1A_L            0.229288\n",
      "DIABLO_Squared      0.235278\n",
      "TRIM62              0.247285\n",
      "cyto.cat=diploid    0.258477\n",
      "MAPT                0.261157\n",
      "YAP1p               0.263526\n",
      "ALBUMIN             0.279360\n",
      "HGB                 0.280275\n",
      "Name: Overall_Survival_cut, dtype: float64\n",
      "ARC                  -0.298773\n",
      "PA2G4.pS65           -0.230169\n",
      "Age.at.Dx            -0.227735\n",
      "PA2G4.pT70           -0.225566\n",
      "PRKCD.pT507          -0.214764\n",
      "ITD                  -0.204119\n",
      "ELK1.pS383_Squared    0.215800\n",
      "TRIM62                0.227335\n",
      "SIRT1_Squared         0.235593\n",
      "HSPA1A_L              0.246880\n",
      "cyto.cat=diploid      0.249926\n",
      "YAP1p                 0.253093\n",
      "H3histon              0.281537\n",
      "H3K27Me3              0.285011\n",
      "HGB                   0.288756\n",
      "Name: Remission_Duration_cut, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Correlation for Continuous variables\n",
    "Corr=pandas.DataFrame()\n",
    "Q_Dependent=Dependent+['Overall_Survival_cut','Remission_Duration_cut']\n",
    "for Variable in Q_Dependent:\n",
    "    C=Q_training[[t for t in Q_training.keys() if (t not in Q_Dependent)]+[Variable]].corr()[Variable][:-1]\n",
    "    Corr=Corr.append(C)\n",
    "#Most important variables for prediction\n",
    "Variables_for_prediction={'pCR':'resp.simple','pRelapse':'Relapse','OS':'Overall_Survival_cut','Remission':'Remission_Duration_cut'}\n",
    "Selected_variables={}\n",
    "for Pred in Variables_for_prediction:\n",
    "    Variable=Variables_for_prediction[Pred]\n",
    "    print Corr.T.sort(Variable)[Variable][Corr.T.sort(Variable)[Variable]**2>0.2**2]\n",
    "    Selected_variables.update({Pred:Corr.T.sort(Variable)[Variable][Corr.T.sort(Variable)[Variable]**2>0.2**2].index})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "In order to predict I created a Prediction Class. The good thing about Classes is that you can create new classes that can heredate the propierties and methods of other Classes. That means that we have don't have to write this part of the code again. So what does this code does?\n",
    "\n",
    "## Creates groups\n",
    "\n",
    "The class contains a function to divide the \n",
    "\n",
    "    Prediction.split(n)\n",
    "    \n",
    "Splits the training set in n parts. n-1 parts will go to the training set, while 1 part will be on the testing set. We create n groups, so each of the n parts can be in the testing set. For example if we split the testing sets in 3 parts (n=3) We will be returned 3 groups that will contain:\n",
    "\n",
    "|Testing|Training|\n",
    "|-------|--------|\n",
    "|1      |2,3     |\n",
    "|2      |1,3     |\n",
    "|3      |1,2     |\n",
    "\n",
    "The output is a list of dictionaries. Here are some examples of how to call the groups:\n",
    "    \n",
    "    groups=Prediction.split(n) #Assign the group to a variable\n",
    "        [{'test':<Table>,'train'<Table>},{'test':<Table>,'train'<Table>},...]\n",
    "    g=groups[0] #Returns the frist dictionary\n",
    "        {'test':<Table>,'train'<Table>}\n",
    "    g['train'] #Returns the training set\n",
    "\n",
    "    Prediction.create_groups(rep,[n])\n",
    "    \n",
    "Will create n groups rep times. This method will invoke split rep times creating a bigger list. It is useful to have more testing and training groups to have a more reliable scoring.\n",
    "    \n",
    "## Predicts\n",
    "\n",
    "### Main prediction function\n",
    "    Prediction.predict(scoring=Scoring_set,out='prediction.csv')\n",
    "    \n",
    "Will give results about the Scoring set using the full training set with the prediction methods used.\n",
    "\n",
    "### Prediction methods\n",
    "\n",
    "    Prediction.pCR(training,testing): \n",
    "Returns a Series containing the probability of Complete Remission ('resp.simple')\n",
    "        \n",
    "    Prediction.pRelapse(training,testing): \n",
    "Returns a Series containing the probability of Relapse ('Relapse')\n",
    "        \n",
    "    Prediction.Remission(training,testing): \n",
    "Returns a Series with the estimated Remission Duration ('Remission_Duration') in weeks (not binned)\n",
    "        \n",
    "    Prediction.OS(training,testing): \n",
    "Returns the estimated Overall Survival ('Overall_Survival') in weeks (not binned)\n",
    "\n",
    "### Reduced prediction methods.\n",
    "The prediction algorithms for pCR and pRelapse should be similar, as well as the algorithms gor Remission and Overall Survival. We can have only two prediction algorithms: pPred for the probabilities prediction and qPred for the time Prediction\n",
    "\n",
    "    Prediction.pPred(training,testing,var):\n",
    "Returns the Probability prediction as a Series. \n",
    "Should return a value between 0 and 1.\n",
    "Used for pCR and pRelapse\n",
    "        \n",
    "    Prediction.qPred(self,training,testing,var):\n",
    "Quantitative prediction, returns the number of weeks.\n",
    "Used for Remission and OS\n",
    "It will be binned after this, so if this is a binned prediction, multiply the result by 52\n",
    " \n",
    "    Prediction._bin(data,bins=[0,52,104])\n",
    "Bins the results as 0,1 2,3. The 0 values correspond to numpy.nan values.\n",
    "\n",
    "## Scoring functions\n",
    "    Prediction.accuracy(self,rep=1,groups=[]):\n",
    "Returns the Balanced accuracy prediction for all the functions\n",
    "    \n",
    "    Prediction.result(self,groups=[],alpha=0.5,Measure='All',rep=1):    \n",
    "Returns the scoring calculations for the prediction as a Table\n",
    "You can select wich scoring to return with Measure\n",
    "alpha allows to select the scoring that is lower than alpha*100% of the scores, supossing a normal distribution.\n",
    "If alpha is 0.5 it will return the mean\n",
    "\n",
    "    Prediction.score(self,groups=[],Measure='All'):\n",
    "Main scoring function\n",
    "Returns a dictionary for all the scores\n",
    "You can select a Measure\n",
    "Will create groups if no group given.\n",
    "\n",
    "### Balanced accuracy (BAC)\n",
    "The Balanced accuracy is an improved scoring function over the accuracy. While the accuracy measures the number of correct gueses over the entire number of guesses, the balanced accuracy measures the number of correct guesses in each subgroup of possible outcomes and then obtains a mean. For example in a population where P=99 and N=1, a random guess where we say that all the population is P would give 99% accuracy, while only having 50% balanced accuracy.\n",
    "\n",
    "|Total population| Positive (P) | Negative (N) |\n",
    "|--|--|--|\n",
    "|Predicted positive| True positive (TP)| False positive (FP)| \n",
    "|Predicted necative| False negative(FN)| True negative (TN)|\n",
    "\n",
    "#### Probabilities\n",
    "For the Balanced accuracy we define a that the predicted positive values are all those values that have a probability greater or equal than 0.5, the rest being predicted negative.\n",
    "\n",
    "$$BAC=\\frac{TP}{P}+\\frac{TN}{N}$$\n",
    "\n",
    "#### Categorical\n",
    "BAC is not strictly defined for continuous variables, so to estimate this scoring method we used the binned results. We have three variables, so a True negative is not defined. We define TP as correct guesses, where the test bin is the same as the predicted bin.\n",
    "\n",
    "$$BAC=\\frac{1}{n} \\sum_{n} \\frac{TP}{P}$$\n",
    "\n",
    "### Area under the receiver operating characteristic curve (AUROC)\n",
    "AUROC is a complimentary analysis to BAC. The ROC curve is a curve that compares the tradeoff between sensitivity and specificity. It create a cutoff by supossing a cutoff (k) on the prediction, where values greater or equal than k will be considered positive, and values smaller than k are considered negative. \n",
    "\n",
    "At k=1 all the predictions are negative, and there are no false negatives nor True positives (We are at point (0,0). As k decreases the number of True positives also increases. \n",
    "\n",
    "If there is a k value where all True positives have been found and there are no false positives, we will be at the point (1,0). If this point is reached AUROC will be 1. \n",
    "\n",
    "When k=0 all predictions are positive and we will arrive at point (1,1).\n",
    "\n",
    "AUROC measures the area under this curve and is not defined for the Categorical dependent variables, since we don't have a parameter \"k\" to modify.\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/8/8c/Receiver_Operating_Characteristic.png>\n",
    "\n",
    "### Pearson correlation coefficient (PCC)\n",
    "Measures the correlation between the predicted values and the actual values. It originally return a value between -1 and 1, but is normalized to be between 0 and 1. For Remission duration and Overall Survival it computes with the real results (not binned). If your prediction return binned results you can unbin them by multiplying by 52 and adding 26.\n",
    "\n",
    "$$PCC = \\frac{\\sum_{i=1}^{n}(p_i-\\overline{p})(a_i-\\overline{a})}{\\sqrt{\\sum_{i=1}^{n}(p_i-\\overline{p})^2}\\sqrt{\\sum_{i=1}^{n}(a_i-\\overline{a})^2}}$$\n",
    "\n",
    "$$PCC_{norm} = (PCC + 1)/2$$\n",
    "\n",
    "### Concordance Index (CI)\n",
    "For each pair of results, it calculates if the predicted results are in the same order than the expected results. For example: for a pair (51,60),(64,62), where 51 and 64 are the predicted values, and 60 and 62 are the expected values. If $51<64$ and $60<62$ (The same relationsip), then $h_{ij}=0$.\n",
    "\n",
    "$$\\sum_{i<j}^{N}h(i,j)$$\n",
    "\n",
    "The pairs that are counted are not censored pairs. A pair is censored if the Overall survival of i is lower than j, but i is alive. If j is equal to i and i or j is alive it is also censored. Nevertheless, if the Overall Survival of j is lower and i and j is alive it is not censored (...Please tell me if you can understand that). A similar relation is applied to Relapse Status with Remission, so it does not matter whether the patients were alive or dead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              AUROC       BAC        CI       PCC\n",
      "pCR        0.526783  0.500000       NaN  0.518470\n",
      "pRelapse   0.488708  0.500000       NaN  0.485310\n",
      "OS              NaN  0.333333  0.546221  0.471703\n",
      "Remission       NaN  0.340000  0.531452  0.484652\n",
      "\n",
      "[4 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas\n",
    "from scipy.stats import norm\n",
    "Training_set=Q_training\n",
    "Scoring_set=Q_scoring\n",
    "Variables_for_prediction={'pCR':'resp.simple','pRelapse':'Relapse','OS':'Overall_Survival','Remission':'Remission_Duration'}\n",
    "class Prediction:\n",
    "    ########################\n",
    "    ##   Initialization   ##\n",
    "    ########################\n",
    "    def __init__(self,training=Training_set,PredVar=Variables_for_prediction):\n",
    "        self.training=training\n",
    "        self.PredVar=PredVar\n",
    "    \n",
    "    ######################\n",
    "    ##  Group Creation  ##\n",
    "    ######################\n",
    "    \n",
    "    def create_groups(self,rep,n=5):\n",
    "        #Creates rep*n training and testing groups\n",
    "        Groups=[]\n",
    "        for i in range(rep):\n",
    "            Groups+=self.split(n)\n",
    "        return Groups\n",
    "    \n",
    "    def split(self,n=5):\n",
    "        #Divides the training groups n times, to have training and testing groups.\n",
    "        #The testing group will contain 1/n of the data\n",
    "        #It returns a list of dictionaries.\n",
    "        #To call a group use for example groups[0]['test']\n",
    "        #That will return the first testing group\n",
    "        training_keys=self.training.T.keys().get_values().copy()\n",
    "        random.shuffle(training_keys)\n",
    "        sublist=np.array_split(training_keys,n)\n",
    "        groups=[]\n",
    "        for i in range(n):\n",
    "            train=[]\n",
    "            test=[]\n",
    "            for j in range(n):\n",
    "                sl=list(sublist[j])\n",
    "                if j<>i:\n",
    "                    train+=sl\n",
    "                else:\n",
    "                    test+=sl\n",
    "            train.sort()\n",
    "            test.sort()\n",
    "            groups+=[{'train':self.training.loc[train],'test':self.training.loc[test]}]\n",
    "        return groups\n",
    "    \n",
    "    \n",
    "    ####################\n",
    "    ##   Prediction   ##\n",
    "    ####################\n",
    "    \n",
    "    def predict(self,scoring=Scoring_set,out='prediction.csv'):\n",
    "        #Main prediction function.\n",
    "        #Returns the result of the prediction for the Scoring set as a csv\n",
    "        #Also prints the results\n",
    "        with open(out,'w+') as handle:\n",
    "            handle.write('#Patient_id, pCR, pRelapse, Remission, OS\\n')\n",
    "            print '#Patient_id, pCR, pRelapse, Remission, OS'\n",
    "            Data=zip(scoring.T.keys(),\n",
    "                     self.pCR(self.training,scoring),\n",
    "                     self.pRelapse(self.training,scoring),\n",
    "                     self._bin(self.Remission(self.training,scoring)),\n",
    "                     self._bin(self.OS(self.training,scoring)))\n",
    "            for d in Data:\n",
    "                handle.write(','.join(str(k) for k in d)+'\\n')\n",
    "                print ','.join(str(k) for k in d)\n",
    "    \n",
    "    \n",
    "    def pCR(self,training,testing): \n",
    "        #Returns the probability of Complete Remission ('resp.simple')\n",
    "        return self.pPred(training,testing,'pCR')\n",
    "        \n",
    "    def pRelapse(self,training,testing): \n",
    "        #Returns the probability of Relapse ('Relapse')\n",
    "        return self.pPred(training,testing,'pRelapse')\n",
    "        \n",
    "    def Remission(self,training,testing): \n",
    "        #Returns the estimated Remission Duration ('Remission_Duration') in weeks (not binned)\n",
    "        return self.qPred(training,testing,'Remission')\n",
    "        \n",
    "    def OS(self,training,testing): \n",
    "        #Returns the estimated Overall Survival ('Overall_Survival') in weeks (not binned)\n",
    "        return self.qPred(training,testing,'OS')\n",
    "    \n",
    "    def pPred(self,training,testing,var):\n",
    "        #Probability prediction, should return a value between 0 and 1.\n",
    "        #Used for pCR and pRelapse\n",
    "        avg_p=sum(training[self.PredVar[var]] == True)/float(len(training))\n",
    "        #print avg_p\n",
    "        return pandas.Series([avg_p+random.random()*1E-6 for i in range(len(testing))],index=testing.index)\n",
    "        \n",
    "    def qPred(self,training,testing,var):\n",
    "        #Quantitative prediction, returns the number of weeks.\n",
    "        #Used for Remission and OS\n",
    "        #It will be binned after this, so if this is a binned prediction, multiply the result by 52\n",
    "        count=np.bincount(self._bin(training[self.PredVar[var]]))\n",
    "        count[0]=0 #bin 0 is nan, do not count nan\n",
    "        val=range(len(count))\n",
    "        val.sort(key=lambda i: count[i],reverse=True)\n",
    "        mode=(val[0]-1)*52.0+26\n",
    "        return pandas.Series([mode+random.random()*1E-2 for i in range(len(testing))],index=testing.index)\n",
    "    \n",
    "    def _bin(self,data,bins=[0,52,104]):\n",
    "        #This function will bin the results from Remission and Overall Survival as expected    \n",
    "        bins = np.array(bins)\n",
    "        digitized = numpy.digitize(data, bins)\n",
    "        for i,v in enumerate(data):\n",
    "            if np.isnan(v):\n",
    "                digitized[i]=0\n",
    "        return digitized\n",
    "\n",
    "    \n",
    "    ######################\n",
    "    ## Scoring methods  ##\n",
    "    ######################\n",
    "    \n",
    "    def accuracy(self,rep=1,groups=[]):\n",
    "        #Returns the Balanced accuracy prediction for all the functions\n",
    "        groups=self.create_groups(rep) if groups==[] else groups\n",
    "        S=self.score(Measure='BAC',groups=groups)\n",
    "        return {s:numpy.mean(S[s]['BAC']) for s in S}\n",
    "    \n",
    "    def result(self,rep=1,groups=[],alpha=0.5,Measure='All'):    \n",
    "        #Returns the scoring calculations for the prediction\n",
    "        #You can select wich scoring to return with Measure\n",
    "        #alpha allows to select the scoring that is lower than alpha*100% of the scores, supossing a normal distribution.\n",
    "        #If alpha is 0.5 it will return the mean\n",
    "        groups=self.create_groups(rep) if groups==[] else groups\n",
    "        S=self.score(groups,Measure)\n",
    "        T=pandas.concat([pandas.Series({key:numpy.mean(S[v][key])-norm.ppf(alpha)*numpy.std(S[v][key]) for key in S[v]},name=v) for v in S],axis=1)\n",
    "        return T.T\n",
    "        #return  {'pCR':pCR_Error,'pRelapse':pRelapse_Error,'Remission':Remission_Error,'OS':OS_Error}\n",
    "        #pRelapse_Error\n",
    "    \n",
    "    def score(self,groups=[],Measure='All'):\n",
    "        #Main scoring function\n",
    "        #Returns a dictionary for all the scores\n",
    "        #You can select a Measure\n",
    "        #Will create groups if no group given.\n",
    "\n",
    "        #Define groups if not defined\n",
    "        groups=self.split() if groups==[] else groups\n",
    "        \n",
    "        #Initialize score dictionary\n",
    "        lg=range(len(groups))\n",
    "        S={'pCR':{},'pRelapse':{},'Remission':{},'OS':{}}\n",
    "        [S[v].update({'BAC':[0 for r in lg],'PCC':[0 for r in lg]})for v in S]\n",
    "        [S[v].update({'AUROC':[0 for r in lg]})for v in ['pCR','pRelapse']]\n",
    "        [S[v].update({'CI':[0 for r in lg]})for v in ['OS','Remission']]\n",
    "        #Independent=[v for v in self.training.keys() if v not in Dependent]\n",
    "        for i,g in enumerate(groups):\n",
    "            train=g['train']\n",
    "            test=g['test']#[Independent]\n",
    "            \n",
    "            #Train and evaluate\n",
    "            pCR_values=self.pCR(train,test)\n",
    "            pRelapse_values=self.pRelapse(train,test)\n",
    "            Remission_values=self.Remission(train,test)\n",
    "            OS_values=self.OS(train,test)\n",
    "            \n",
    "            #Compare the expeced values to the obtained values\n",
    "            #test=g['test']\n",
    "            \n",
    "            #Calculate the BAC scores\n",
    "            if Measure in ['All','BAC']:\n",
    "                S['pCR']['BAC'][i]=self._pBAC(pCR_values,test['resp.simple'])\n",
    "                S['pRelapse']['BAC'][i]=self._pBAC(pRelapse_values,test['Relapse'])\n",
    "                S['Remission']['BAC'][i]=self._cBAC(self._bin(Remission_values),self._bin(test['Remission_Duration']))\n",
    "                S['OS']['BAC'][i]=self._cBAC(self._bin(OS_values),self._bin(test['Overall_Survival']))\n",
    "                if Measure=='BAC':\n",
    "                    continue\n",
    "            \n",
    "            #Calculate the PCC scores\n",
    "            if Measure in ['All','PCC']:\n",
    "                S['pCR']['PCC'][i]=self._pPCC(pCR_values,test['resp.simple'])\n",
    "                S['pRelapse']['PCC'][i]=self._pPCC(pRelapse_values,test['Relapse'])\n",
    "                S['Remission']['PCC'][i]=self._pPCC(Remission_values,test['Remission_Duration'])\n",
    "                S['OS']['PCC'][i]=self._pPCC(OS_values,test['Overall_Survival'])\n",
    "                if Measure=='PCC':\n",
    "                    continue\n",
    "            \n",
    "            #Calculate the AUROC scores\n",
    "            if Measure in ['All','AUROC']:\n",
    "                S['pCR']['AUROC'][i]=self._AUROC(pCR_values,test['resp.simple'])\n",
    "                S['pRelapse']['AUROC'][i]=self._AUROC(pRelapse_values,test['Relapse'])\n",
    "                if Measure=='AUROC':\n",
    "                    continue\n",
    "            \n",
    "            #Calculate the CI scores\n",
    "            if Measure in ['All','CI']:\n",
    "                S['Remission']['CI'][i]=self._RCI(Remission_values,test)\n",
    "                S['OS']['CI'][i]=self._OSCI(OS_values,test)\n",
    "                if Measure=='CI':\n",
    "                    continue           \n",
    "        \n",
    "        return S\n",
    "    \n",
    "    def _pBAC(self,predicted,expected):\n",
    "        #print predicted\n",
    "        #print expected\n",
    "        TP=float(((predicted>=0.5) & (expected>=0.5)).dropna().sum())\n",
    "        TN=float(((predicted<0.5) & (expected<0.5)).dropna().sum())\n",
    "        P=max(float((expected>=0.5).dropna().sum()),1E-64)\n",
    "        N=max(float((expected<0.5).dropna().sum()),1E-64)\n",
    "        return (TP/P+TN/N)/2\n",
    "\n",
    "    \n",
    "    def _cBAC(self,predicted,expected):\n",
    "        TV=[]\n",
    "        a=set(expected)\n",
    "        for val in set(a):\n",
    "            if val>0:\n",
    "                TP=float(((predicted==val) & (expected==val)).sum())\n",
    "                P=max(float((expected==val).sum()),1E-64)\n",
    "                TV+=[TP/P]\n",
    "        return numpy.mean(TV)\n",
    "        \n",
    "    def _AUROC(self,predicted,expected):\n",
    "        AUC=0\n",
    "        TPRl=0\n",
    "        FPRl=0\n",
    "        K=list(set(numpy.concatenate((predicted,[1.0,0.0]))))\n",
    "        K.sort(reverse=True)\n",
    "        #print K\n",
    "        for k in K:\n",
    "            T=(predicted>=k)\n",
    "            TP=((expected==1) & (T==1)).sum()\n",
    "            FP=((expected==0) & (T==1)).sum()\n",
    "            TPR=TP/max(float(expected.sum()),1E-64)#may be 0 sometimes\n",
    "            FPR=FP/max(float((expected==0).sum()),1E-64)#may be 0 sometimes   \n",
    "            AUC+=TPRl*(FPR-FPRl)\n",
    "            FPRl=FPR\n",
    "            TPRl=TPR\n",
    "        return AUC\n",
    "            \n",
    "    \n",
    "    def _OSCI(self,predicted,expected):        \n",
    "        c=0.0\n",
    "        H=0.0\n",
    "        for i,ai,pi,Ai in zip(range(len(predicted)),predicted,expected['Overall_Survival'],expected['vital.status']):\n",
    "            if numpy.isnan(ai) or numpy.isnan(pi):\n",
    "                continue\n",
    "            for j,aj,pj,Aj in zip(range(len(predicted)),predicted,expected['Overall_Survival'],expected['vital.status']):\n",
    "                if i>=j:\n",
    "                    continue\n",
    "                if numpy.isnan(aj) or numpy.isnan(pj):\n",
    "                    continue\n",
    "                if ai<=aj and Ai: #The patient i has smaller Survival but is still alive\n",
    "                    continue\n",
    "                if aj==ai and Aj: #The patient j has smaller Survival but is still alive\n",
    "                    continue\n",
    "                \n",
    "                if numpy.sign(round(ai-aj,5))==numpy.sign(round(pi-pj,5)):\n",
    "                    #print ai,aj,pi,pj\n",
    "                    H+=1\n",
    "                    c+=1\n",
    "                else:\n",
    "                    #H+=0\n",
    "                    c+=1\n",
    "        #print H,c\n",
    "        return H/c\n",
    "                    \n",
    "    def _RCI(self,predicted,expected):\n",
    "        c=0.0\n",
    "        H=0.0\n",
    "        for i,ai,pi,Ai in zip(range(len(predicted)),predicted,expected['Remission_Duration'],expected['Relapse']):\n",
    "            if numpy.isnan(ai) or numpy.isnan(pi):\n",
    "                continue\n",
    "            for j,aj,pj,Aj in zip(range(len(predicted)),predicted,expected['Remission_Duration'],expected['Relapse']):\n",
    "                if i>=j:\n",
    "                    continue\n",
    "                if numpy.isnan(aj) or numpy.isnan(pj): #no value on Relapse\n",
    "                    continue\n",
    "                if ai<=aj and not Ai: #The patient i has smaller Remission but has not Relapsed\n",
    "                    continue\n",
    "                if aj==ai and not Aj: #The patient j has smaller Remission but has not Relapsed\n",
    "                    continue\n",
    "                \n",
    "                if numpy.sign(round(ai-aj,5))==numpy.sign(round(pi-pj,5)):\n",
    "                    #print ai,aj,pi,pj\n",
    "                    H+=1\n",
    "                    c+=1\n",
    "                else:\n",
    "                    #H+=0\n",
    "                    c+=1\n",
    "        #print H,c\n",
    "        return H/c\n",
    "    \n",
    "    def _pPCC(self,predicted,expected): #Pearson Correlation Coeficient\n",
    "        A=pandas.concat([predicted,expected],axis=1,keys=['pred','exp'])\n",
    "        A=A.dropna() #drop data that has na as a result\n",
    "        p=A['pred'].mean()\n",
    "        a=A['exp'].mean()\n",
    "        sp=max(((A['pred']-p)**2).sum()**0.5,1E-64) #Sometimes this is 0, then S=0 too\n",
    "        sa=max(((A['exp']-a)**2).sum()**0.5,1E-64) #Sometimes this is 0, then S=0 too\n",
    "        S=(A['pred']-p)*(A['exp']-a)\n",
    "        #print S.sum(),sp,sa\n",
    "        return (S.sum()/sp/sa+1)/2\n",
    "\n",
    "Dummy=Prediction()\n",
    "print Dummy.result(alpha=0.5,Measure='All',rep=5)\n",
    "#Dummy.predict()\n",
    "#Dummy._pPCC(pandas.Series([-200,+50,-200,+120,-120,+100,-200]),pandas.Series([0,2,0,1,1,3,0]))\n",
    "#print Dummy.accuracy(100)\n",
    "#print Dummy.accuracy(100)\n",
    "#print Dummy.accuracy(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "To modify the previous class you can change the Qpred and Cpred methods.\n",
    "For the linear regression I also modified the create_groups methods, since the Linear regression algorithm will not accept NaN values. You cn also modify the \\__init\\__ class to incorporate variables used at the initialization of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              AUROC       BAC        CI       PCC\n",
      "pCR        0.485996  0.500000       NaN  0.489981\n",
      "pRelapse   0.514349  0.500000       NaN  0.515842\n",
      "OS              NaN  0.333333  0.556484  0.494843\n",
      "Remission       NaN  0.333333  0.541715  0.497595\n",
      "\n",
      "[4 rows x 4 columns]\n",
      "              AUROC       BAC        CI       PCC\n",
      "pCR        0.948839  0.867869       NaN  0.882124\n",
      "pRelapse   0.779851  0.662110       NaN  0.725374\n",
      "OS              NaN  0.469243  0.682276  0.724936\n",
      "Remission       NaN  0.484968  0.675286  0.732501\n",
      "\n",
      "[4 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "\n",
    "Good_variables={'pCR': [u'KDR_Squared', u'ATF3', u'RPS6_Squared', u'cyto.cat=Misc', u'GATA3', u'CDKN2A_Squared', u'NF2.pS518', u'CASP9.cl315_Squared', u'IGFBP2', u'SMAD3_Squared', u'PRKAA1_2.pT172_Squared', u'HDAC3_Squared', u'CLPP', u'PRIOR.MAL', u'ATG7', u'cyto.cat=diploid', u'DLX1_Squared', u'MSI2', u'CCNE2', u'NPM1.3542', u'ARC', u'cyto.cat=21', u'ITGAL', u'SMAD2_Squared', u'RPS6.pS240_244', u'MYC', u'LCK_Squared', u'ITGA2', u'GAPDH', u'CCNE1', u'PA2G4.pT70_Squared', u'cyto.cat=-7', u'MTOR.pS2448_Squared', u'CD44', u'PRKCB.II_Squared', u'MAP2K1_2.pS217_221_Squared', u'BAD.pS136_Squared', u'CASP9.cl330', u'GSKA_B.pS21_9', u'CTSG', u'FOXO3_Squared', u'TGM2', u'STAT3.pS727', u'CASP8_Squared', u'PIK3CA', u'RPS6', u'SFN', u'PTK2_Squared', u'ZNF296_Squared', u'PRKCD.pT507', u'Age.at.Dx', u'STMN1_Squared', u'YWHAZ_Squared', u'HSPB1', u'STMN1', u'PDK1.pS241_Squared', u'CDK1', u'MAPK9'],\n",
    "                'pRelapse': [u'cyto.cat=t9;22', 'IGFBP2_Squared', u'CCND3', u'KIT_Squared', u'PTEN.pS380T382T383', u'BCL2_Squared', u'BAK1_Squared', u'SMAD5.pS463_Squared', 'MDM2', 'ARC', u'PTPN11_Squared', u'H3histon_Squared', u'PA2G4.pS65_Squared', 'HDAC1_Squared', u'EIF2S1.pS51._Squared'], \n",
    "                'OS': [u'PRIOR.MAL', u'ARC', u'cyto.cat=diploid', u'H3histon', u'Age.at.Dx', u'PTGS2_Squared', u'SMAD4', u'PA2G4.pS65', u'STMN1', u'EIF2AK2', u'H3K27Me3', u'HSP90AA1_B1'], \n",
    "                'Remission': [u'CASP9.cl330', u'ERG', u'ALBUMIN', u'CASP3.cl175', u'TP53', u'RPS6KB1.pT389', u'PLAC1', u'JMJD6', u'SMAD3_Squared', u'ERG_Squared', u'TRIM24', u'Age.at.Dx', u'HSPA1A_L', u'ATG7_Squared', u'ARC_Squared', u'STAT3.pS727', u'CBL_Squared', u'BIRC5_Squared', u'ARC', u'YWHAE', u'SMAD5.pS463', u'BRAF_Squared', u'MTOR.pS2448_Squared']}\n",
    "\n",
    "All_variables={'pCR':[v for v in Q_training.keys() if v not in Q_Dependent],\n",
    "               'pRelapse':[v for v in Q_training.keys() if v not in Q_Dependent],\n",
    "               'Remission':[v for v in Q_training.keys() if v not in Q_Dependent],\n",
    "               'OS':[v for v in Q_training.keys() if v not in Q_Dependent]}\n",
    "\n",
    "Variables_for_prediction={'pCR':'resp.simple','pRelapse':'Relapse','OS':'Overall_Survival','Remission':'Remission_Duration'}\n",
    "\n",
    "class LinearRegression(Prediction):\n",
    "    def __init__(self,training=Training_set,pivot=All_variables,PredVar=Variables_for_prediction):\n",
    "        self.training=training\n",
    "        self.pivot=pivot\n",
    "        self.ols=linear_model.LinearRegression()\n",
    "        self.PredVar=PredVar\n",
    "        \n",
    "    def create_groups(self,rep):\n",
    "        Groups=[]\n",
    "        for i in range(rep):\n",
    "            Groups+=self.split()\n",
    "        New_Groups=[]\n",
    "        for g in Groups:\n",
    "            training=g['train']\n",
    "            testing=g['test']\n",
    "            Accept=True\n",
    "            for dep in All_variables.keys():\n",
    "                ind=All_variables[dep]\n",
    "                #ind=pandas.concat([training[ind],testing[ind]]).dropna(axis=1).keys()\n",
    "                A=pandas.concat([training[ind],pandas.DataFrame(training[self.PredVar[dep]])],axis=1,keys=['ind','dep'])\n",
    "                A=A.dropna()\n",
    "                if len(A['dep',])<=0:\n",
    "                    Accept=False\n",
    "            if Accept:\n",
    "                New_Groups+=[g]\n",
    "        return New_Groups\n",
    "    \n",
    "    def pPred(self,training,testing,dep):\n",
    "        ind=self.pivot[dep] #Select independent variables\n",
    "        #ind=pandas.concat([training[ind],testing[ind]]).dropna(axis=1).keys() #drop variables that have na\n",
    "        A=pandas.concat([training[ind],pandas.DataFrame(training[self.PredVar[dep]])],axis=1,keys=['ind','dep'])\n",
    "        A=A.dropna() #drop data that has na as a result\n",
    "        self.ols.fit(A['ind',],A['dep',]) #train\n",
    "        test=testing[ind].dropna()\n",
    "        Results=self.ols.predict(test).T[0] #predict\n",
    "        for i,val in enumerate(Results):\n",
    "            if val>1:\n",
    "                Results[i]=1\n",
    "            if val<0:\n",
    "                Results[i]=0\n",
    "        R=pandas.Series(Results,index=test.index)\n",
    "        return pandas.Series(R,index=testing.index)\n",
    "        \n",
    "    def qPred(self,training,testing,dep):\n",
    "        ind=self.pivot[dep] #Select independent variables\n",
    "        #ind=pandas.concat([training[ind],testing[ind]]).dropna(axis=1).keys() #drop variables that have na\n",
    "        A=pandas.concat([training[ind],pandas.DataFrame(training[self.PredVar[dep]])],axis=1,keys=['ind','dep'])\n",
    "        A=A.dropna() #drop data that has na as a result\n",
    "        self.ols.fit(A['ind',],A['dep',]) #train\n",
    "        test=testing[ind].dropna()\n",
    "        Results=self.ols.predict(test).T[0] #predict\n",
    "        for i,val in enumerate(Results):\n",
    "            if val<0:\n",
    "                Results[i]=0\n",
    "        R=pandas.Series(Results,index=test.index)\n",
    "        return pandas.Series(R,index=testing.index)\n",
    "    \n",
    "LR=LinearRegression(pivot=Good_variables)\n",
    "print Dummy.result(rep=10)\n",
    "print LR.result(rep=10)\n",
    "Groups=LR.create_groups(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution\n",
    "\n",
    "From this point we should see which combination of variables (or parameters, depending or your algorithm) will be better.\n",
    "I though that for the variables a three phased alghoritm may be useful.\n",
    "On the first phase we can check wether each variable can predict accurately anything.\n",
    "On the second phase we can check if combination of variables can predict better than any single variable.\n",
    "On the third phase we can create new combination of variables doing bolder changes, like mixing groups,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              AUROC       BAC        CI       PCC\n",
      "pCR        0.951366  0.859863       NaN  0.885330\n",
      "pRelapse   0.796439  0.735013       NaN  0.753998\n",
      "OS              NaN  0.522617  0.711447  0.709072\n",
      "Remission       NaN  0.435919  0.688941  0.740880\n",
      "\n",
      "[4 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Initialization\n",
    "#Make your best guess here\n",
    "Variables_for_prediction={'pCR':'resp.simple','pRelapse':'Relapse','OS':'Overall_Survival_cut','Remission':'Remission_Duration_cut'}\n",
    "\n",
    "Good_variables={'pCR': [u'KDR_Squared', u'ATF3', u'RPS6_Squared', u'cyto.cat=Misc', u'GATA3', u'CDKN2A_Squared', u'NF2.pS518', u'CASP9.cl315_Squared', u'IGFBP2', u'SMAD3_Squared', u'PRKAA1_2.pT172_Squared', u'HDAC3_Squared', u'CLPP', u'PRIOR.MAL', u'ATG7', u'cyto.cat=diploid', u'DLX1_Squared', u'MSI2', u'CCNE2', u'NPM1.3542', u'ARC', u'cyto.cat=21', u'ITGAL', u'SMAD2_Squared', u'RPS6.pS240_244', u'MYC', u'LCK_Squared', u'ITGA2', u'GAPDH', u'CCNE1', u'PA2G4.pT70_Squared', u'cyto.cat=-7', u'MTOR.pS2448_Squared', u'CD44', u'PRKCB.II_Squared', u'MAP2K1_2.pS217_221_Squared', u'BAD.pS136_Squared', u'CASP9.cl330', u'GSKA_B.pS21_9', u'CTSG', u'FOXO3_Squared', u'TGM2', u'STAT3.pS727', u'CASP8_Squared', u'PIK3CA', u'RPS6', u'SFN', u'PTK2_Squared', u'ZNF296_Squared', u'PRKCD.pT507', u'Age.at.Dx', u'STMN1_Squared', u'YWHAZ_Squared', u'HSPB1', u'STMN1', u'PDK1.pS241_Squared', u'CDK1', u'MAPK9'],\n",
    "                'pRelapse': [u'cyto.cat=t9;22', 'IGFBP2_Squared', u'CCND3', u'KIT_Squared', u'PTEN.pS380T382T383', u'BCL2_Squared', u'BAK1_Squared', u'SMAD5.pS463_Squared', 'MDM2', 'ARC', u'PTPN11_Squared', u'H3histon_Squared', u'PA2G4.pS65_Squared', 'HDAC1_Squared', u'EIF2S1.pS51._Squared', u'HGB', u'TP53', u'GAPDH_Squared', u'ERG', u'SIRT1_Squared', u'BCL2L1', u'XIAP', u'EGFR.pY992_Squared', u'HDAC3', u'ODC1_Squared'], \n",
    "                'OS': [u'SMAD2.pS465_Squared', u'EIF2S1', u'Age.at.Dx', u'NF2_Squared', u'DIABLO_Squared', u'cyto.cat=-5,-7', u'RPS6KB1', u'MAPT', u'HSPA1A_L', u'HGB', u'MAPK9_Squared', u'ERG_Squared', u'VHL_Squared', u'SMAD2.pS245_Squared', u'PARK7', u'CTSG_Squared', u'WTAP_Squared', u'TRIM62', u'ZNF296', u'AIFM1_Squared', u'DLX1', u'cyto.cat=diploid', u'H3K27Me3', u'H3K4Me2_Squared', u'BAD.pS155', u'CCND3', u'HSP90AA1_B1', u'YAP1p', u'GSKA_B.pS21_9_Squared', u'FN1', u'BAD.pS136', u'ALBUMIN', u'AKT1_2_3.pT308'], \n",
    "                'Remission': [u'CASP9.cl330', u'ERG', u'ALBUMIN', u'CASP3.cl175', u'TP53', u'RPS6KB1.pT389', u'PLAC1', u'JMJD6', u'SMAD3_Squared', u'ERG_Squared', u'TRIM24', u'Age.at.Dx', u'HSPA1A_L', u'ATG7_Squared', u'ARC_Squared', u'STAT3.pS727', u'CBL_Squared', u'BIRC5_Squared', u'ARC', u'YWHAE', u'SMAD5.pS463', u'BRAF_Squared', u'MTOR.pS2448_Squared']}\n",
    "\n",
    "Best_LR=LinearRegression(pivot=Good_variables,PredVar=Variables_for_prediction)\n",
    "groups=Best_LR.create_groups(50)\n",
    "Best_result=Best_LR.accuracy(groups=groups)\n",
    "Best_LR_result=Best_LR.score(groups=groups,Measure='BAC')\n",
    "print Best_LR.result(rep=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Good_variables.update({'pCR': [u'KDR_Normalized', u'ATF3', u'RPS6_Normalized', u'cyto.cat=Misc', u'GATA3', u'CDKN2A_Normalized', u'NF2.pS518', u'CASP9.cl315_Normalized', u'IGFBP2', u'SMAD3_Normalized', u'PRKAA1_2.pT172_Normalized', u'HDAC3_Normalized', u'CLPP', u'PRIOR.MAL', u'ATG7', u'cyto.cat=diploid', u'DLX1_Normalized', u'MSI2', u'CCNE2', u'NPM1.3542', u'ARC', u'cyto.cat=21', u'ITGAL', u'SMAD2_Normalized', u'RPS6.pS240_244', u'MYC', u'LCK_Normalized', u'ITGA2', u'GAPDH', u'CCNE1', u'PA2G4.pT70_Normalized', u'cyto.cat=-7', u'MTOR.pS2448_Normalized', u'CD44', u'PRKCB.II_Normalized', u'MAP2K1_2.pS217_221_Normalized', u'BAD.pS136_Normalized', u'CASP9.cl330', u'GSKA_B.pS21_9', u'CTSG', u'FOXO3_Normalized', u'TGM2', u'STAT3.pS727', u'CASP8_Normalized', u'PIK3CA', u'RPS6', u'SFN', u'PTK2_Normalized', u'ZNF296_Normalized', u'PRKCD.pT507', u'Age.at.Dx', u'STMN1_Normalized', u'YWHAZ_Normalized', u'HSPB1', u'STMN1', u'PDK1.pS241_Normalized', u'CDK1', u'MAPK9']})\n",
    "#Good_variables.update({'pRelapse': [u'cyto.cat=t9;22', 'IGFBP2_Normalized', u'CCND3', u'KIT_Normalized', u'PTEN.pS380T382T383', u'BCL2_Normalized', u'BAK1_Normalized', u'SMAD5.pS463_Normalized', 'MDM2', 'ARC', u'PTPN11_Normalized', u'H3histon_Normalized', u'PA2G4.pS65_Normalized', 'HDAC1_Normalized', u'EIF2S1.pS51._Normalized', u'SMAD6_Normalized', u'AKT1_Normalized']})\n",
    "#Good_variables.update({'OS':['Age.at.Dx','HGB','cyto.cat=diploid','H3K27Me3','ARC']})\n",
    "#Good_variables.update({'Remission':['ARC','SIRT1_Normalized','HGB','Age.at.Dx','ELK1.pS383_Normalized','cyto.cat=diploid','GAPDH_Normalized','STMN1','ERG','CCND1','CD13','HSPA1A_L','TP53']})\n",
    "\n",
    "import time\n",
    "\n",
    "i=0 #Iteration number counter\n",
    "Stop=time.time()+60*60*1 #Stop time in seconds\n",
    "\n",
    "Update_Best=False #Only update best if conditions apply\n",
    "\n",
    "#Try to make better predictions\n",
    "while time.time()<Stop:  \n",
    "    i=i+1  \n",
    "    #Change the variables\n",
    "    Test_variables={}\n",
    "    for key in Selected_variables:\n",
    "        #Choose variable pool:\n",
    "        Rnd=random.random()\n",
    "        if Rnd>0.9:\n",
    "            Pool=All_variables #Contains everything, they won't help mostly\n",
    "        elif Rnd>0.3:\n",
    "            #Something in between (but costs a bit to compute)\n",
    "            cutoff=0.2-0.2*(Rnd-0.3)**.5/(0.9-0.3)**.5\n",
    "            Pool={}\n",
    "            for Pred in Variables_for_prediction:\n",
    "                Variable=Variables_for_prediction[Pred]\n",
    "                Pool.update({Pred:Corr.T.sort(Variable)[Variable][Corr.T.sort(Variable)[Variable]**2>cutoff**2].index})\n",
    "        else:\n",
    "            Pool=Selected_variables #Best variables  \n",
    "        #Choose the change\n",
    "        Rnd=random.random()\n",
    "        if Rnd>0.7: #Sometimes drop a variable\n",
    "            l=len(Good_variables[key])\n",
    "            n=max(l-random.randint(1,5),1)\n",
    "            Test_variables.update({key:random.sample(Good_variables[key],n)})\n",
    "        elif Rnd>0.2: #Sometimes add a value\n",
    "            varis=[v for v in Pool[key] if v not in Good_variables[key]]\n",
    "            l=len(varis)\n",
    "            n=min(random.randint(1,5),l)\n",
    "            Test_variables.update({key:Good_variables[key]+random.sample(varis,n)})\n",
    "        else: #Sometimes choose something completely random\n",
    "            l=min(len(Pool[key]),len(Good_variables[key])*2)\n",
    "            Test_variables.update({key:random.sample(Pool[key],random.randint(1,l))})\n",
    "\n",
    "    #Create a linear regression\n",
    "    LR=LinearRegression(pivot=Test_variables,PredVar=Variables_for_prediction)\n",
    "    result=LR.accuracy(10)\n",
    "    \n",
    "    #Test against best prediction\n",
    "    Next=True\n",
    "    for key in result:\n",
    "        if result[key]>Best_result[key]:\n",
    "            Next=False\n",
    "    if Next:\n",
    "        continue\n",
    "    \n",
    "    #Test how many times it has a better result\n",
    "    LR_result=LR.score(groups=groups,Measure='BAC')\n",
    "    for key in LR_result.keys():\n",
    "        conf=0.0\n",
    "        new_BACs=LR_result[key]['BAC']\n",
    "        old_BACs=Best_LR_result[key]['BAC']\n",
    "        new_BACs.sort()\n",
    "        old_BACs.sort()\n",
    "        pos=0.0\n",
    "        tot=float(len(new_BACs)**2)\n",
    "        for new in new_BACs:\n",
    "            for k,old in enumerate(old_BACs):\n",
    "                if old>new:\n",
    "                    pos+=k\n",
    "                    break\n",
    "        conf=pos/tot\n",
    "        \n",
    "        #If more than 60% are better, update\n",
    "        if conf>0.6:\n",
    "            with open('Good_variables.txt','a+') as handle:\n",
    "                handle.write('Updated: '+key+'\\n')\n",
    "            Good_variables.update({key:Test_variables[key]})\n",
    "            Update_Best=True\n",
    "    \n",
    "    #Update variables\n",
    "    if Update_Best:\n",
    "        Best_LR=LR\n",
    "        groups=Best_LR.create_groups(50)\n",
    "        Best_result=Best_LR.accuracy(groups=groups)\n",
    "        Best_BAC_result=Best_LR.score(groups=groups,Measure='BAC')\n",
    "        with open('Good_variables.txt','a+') as handle:\n",
    "            handle.write(str(Good_variables)+'\\n')\n",
    "            handle.write(str(Best_result)+'\\n')\n",
    "        Update_Best=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print i\n",
    "print Best_LR.result(rep=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Best_LR.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
